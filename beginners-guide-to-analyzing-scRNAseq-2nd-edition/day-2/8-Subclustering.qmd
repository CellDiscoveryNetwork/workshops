---
title: "8 - Subclustering"
author: "CDN team"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    toc: true
    toc_float: true
    toc-location: left
    toc-depth: 4
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = "100%", fig.align='center', 
                      message = FALSE, warning = FALSE, cache = FALSE)
options(width = 1200)
options(repos = c(CRAN = "https://cloud.r-project.org"))
```


## Introduction

In this vignette we will examine methods for increasing resolution on cell subtypes and cell states. We will compare two methods: increasing resolution and other parameters to find more clusters, and subclustering. Subclustering is the process of clustering, subsetting to one cluster, then running the clustering pipeline again. In high-dimensional datasets, especially ones with lots of technical or biological noise, focusing on specific celltypes individually improves detection of subtype and state patterns. Highly variable gene selection and latent-space calculation are both affected by noise and outliers. Subclustering can also improve computational efficiency - finding small clusters can be expensive if working with the full dataset. 

However, it's important to keep in mind that iterative subclustering can lead to "overfitting" the data. This means we might identify noise as clusters, and we will have to contend more with the "curse of dimensionality" in downstream analysis. We should always validate our clusters according to expression of marker genes, use technical replicates, bootstrapping methods, or check their existence in external datasets. 

### Vocabulary

**Subclustering**

The process of dividing a previously identified cluster into smaller, more detailed clusters (subclusters). Subclustering is used to uncover finer, often subtle distinctions within a dataset that might not be visible in an initial analysis.

**Overfitting**

Overfitting is when an analyst describes random noise in the data rather than underlying general relationships. Overfit models perform well on their dataset, but very poorly on other data. 

**Curse of Dimensionality**

The term data analysts use to describe phenomena that appear when analyzing data in high-dimensional spaces. As dimensionality increases, the data can become sparse. Sparsity is problematic for statistical significance testing. Additionally, by increasing dimensions, we increase the number of false positives when using p-value thresholds.

**Parameter scan** 

AKA parameter sweep, this is the process of systematically varying parameters in an algorithm to analyze the effects of their changes on the outcome. Parameter scans are widely used in computationaly biology to identify optimal parameters or test the stability of our models. 

## Key Takeaways

-   Recomputing highly variable genes at each subclustering step resets the biological universe we are looking at to the capture the "new" sources of variability.

-   Iterative subclustering is essential to uncover fine grained populations

-   In addition to finding fine-grained populations, subclustering can help create better divisions between the different "species" of celltypes and subtypes.

## Libraries

```{r message=FALSE, warning=FALSE}

### Make sure all the packages are installed
if (!requireNamespace("Seurat", quietly = TRUE))
    install.packages("Seurat")

if (!requireNamespace("tidyverse", quietly = TRUE))
    install.packages("tidyverse")

if (!requireNamespace("devtools", quietly = TRUE))
    install.packages("devtools")

if (!requireNamespace("colorBlindness", quietly = TRUE))
    install.packages("colorBlindness")

if (!requireNamespace("DT", quietly = TRUE))
    install.packages("DT")    

if (!requireNamespace("scales", quietly = TRUE))
    install.packages("scales") 

if (!requireNamespace("tictoc", quietly = TRUE))
    install.packages("tictoc") 

if (!requireNamespace("ggalluvial", quietly = TRUE))
    install.packages("ggalluvial") 

### Load all the necessary libraries
library(Seurat)
library(tidyverse)
library(devtools)
library(colorBlindness)
library(DT)
library(scales)
library(RColorBrewer)
library(scales)
library(tictoc)
library(ggalluvial)

set.seed(687)
```

## Load data

We're going to be working with a dataset from the paper - [Immunophenotyping of COVID-19 and influenza highlights the role of type I interferons in development of severe COVID-19](https://doi.org/10.1126/sciimmunol.abd1554) Download data from the [cellxgene](https://cellxgene.cziscience.com/collections/4f889ffc-d4bc-4748-905b-8eb9db47a2ed) portal.

```{r message=FALSE, warning=FALSE, output=FALSE}
se <- readRDS("../data/se_lvl1.rds")
```

Subset T cell compartment for downstream analysis
```{r}
tse <- se[, se$annotation_lvl1 == "T cells"]
```

### Color palette

```{r}
# Set color palette for cell types
pal <- paletteMartin
names(pal) <- sort(unique(se$Celltype))

donor_pal <- c(
    "#66C2A4", "#41AE76", "#238B45", "#006D2C",
    "#41B6C4", "#1D91C0", "#225EA8", "#253494", "#081D58",
    "#FFEDA0", "#FED976", "#FEB24C", "#f79736", "#FD8D3C",
    "#FC4E2A", "#E31A1C", "#BD0026", "#ad393b", "#800000", "#800050")

names(donor_pal) <- c(
    "Normal 1", "Normal 2", "Normal 3", "Normal 4",
    "Flu 1", "Flu 2", "Flu 3", "Flu 4", "Flu 5",
    "nCoV 1", "nCoV 2", "nCoV 3", "nCoV 4", "nCoV 5",
    "nCoV 6", "nCoV 7", "nCoV 8", "nCoV 9", "nCoV 10", "nCoV 11"  
)
```

### To get up to speed with the previous worksheets, process the data in the same way.

```{r}
se <- se %>%
    NormalizeData(verbose = FALSE) %>%
    FindVariableFeatures(
        method = "vst",
        nfeatures = 3000,
        verbose = FALSE) %>%
    ScaleData(verbose = FALSE, features = VariableFeatures(.))
```

Let's extract the top 3000 HVGs from the whole data across all cell types.
```{r}
hvg_full <- VariableFeatures(se)
```


## Analysis

### Finding rare celltypes

For many of us, our first idea for finding rare celltypes is to modulate the parameters of what we have already to find the right celltypes. As we saw in the previous clustering notebook, we can find NK and T cell clusters this way, but it still seems like there's some heterogeneity in the clusters we've found. For illustration, I've run a parameter scan on the following variables:

- `FindVariableFeatures` nfeatures
- `RunPCA` npcs, 
- `FindNeighbors` k.param, 
- `FindClusters` resolution

```{r fig.width=9, fig.height=9, eval=FALSE}
parameter_df <- expand.grid(
  nf = c(2000, 3000, 5000),
  pc = c(20, 30, 50),
  k = c(10, 30, 50),
  res = c(0.5, 0.8, 1.2)
)

seurat_parameter_scan <- function(srobj, nf, pc, k, res) {
  srobj <- srobj %>%
    NormalizeData() %>%
    FindVariableFeatures(selection.method = "vst", nfeatures = nf) %>%
    ScaleData(features = head(VariableFeatures(object = .), nf)) %>%
    RunPCA(npcs = pc, verbose = FALSE) %>%
    FindNeighbors(dims = 1:pc, k.param = k) %>%
    FindClusters(resolution = res, verbose = FALSE)

  # Extract Idents and name the output vector
  idents <- Idents(srobj)
  names(idents) <- paste("nf", nf, "pc", pc, "k", k, "res", res, sep="_")
  
  return(idents)
}

# Apply the function to each row of parameter_df and combine results into a single data frame
paramscan <- lapply(seq_len(nrow(parameter_df)), function(i) {
  params <- parameter_df[i, ]
  idents_vector <- seurat_parameter_scan(se, params$nf, params$pc, params$k, params$res)
  return(idents_vector)
})

# name cluster columns after parameters used to obtain them
names(paramscan) <- parameter_df %>%
  mutate(params = pmap_chr(., function(...) {
    cols <- colnames(parameter_df)
    values <- list(...)
    paste0(cols, values, collapse = "_")
  })) %>%
  pull(params)

saveRDS(paramscan, '../data/covid_flu_srobj_clusters_paramscan.rds')
```

```{r fig.width=12, fig.height=12}
paramscan <- readRDS('../data/covid_flu_srobj_clusters_paramscan.rds')

paramscan <- bind_cols(paramscan)

row.names(paramscan) <- colnames(se)

paramscan_long <- paramscan %>%
  rownames_to_column(var = "cell_id") %>%
  pivot_longer(
    cols = -cell_id,
    names_to = "parameter",
    values_to = "cluster"
  ) %>%
  mutate(
    nf = as.numeric(gsub(".*nf(\\d+)_.*", "\\1", parameter)),
    pc = as.numeric(gsub(".*pc(\\d+)_.*", "\\1", parameter)),
    k = as.numeric(gsub(".*k(\\d+)_.*", "\\1", parameter)),
    res = as.numeric(gsub(".*res(\\d+\\.\\d+).*", "\\1", parameter))
  ) %>% 
  group_by(parameter) %>% 
  mutate(
    n_clusts = max(as.numeric(cluster))
  ) %>%
  select(-parameter)

ggplot(paramscan_long %>% 
        select(-cell_id, -cluster) %>% 
        distinct, aes(x = factor(pc), 
        y = n_clusts, 
        fill = factor(k))) +
  geom_bar(stat='identity') +
  facet_grid(paste('k=',k) + paste('nf =',nf) ~ paste('resolution =',res)) +
  scale_y_continuous(labels = scales::label_number()) +
  scale_fill_manual(values = unname(donor_pal[c(1,6,11)])) +
  labs(
      title = "Number of clusters Across Parameters",
      x = "Clustering resolution + nPCs",
      y = "Number of clusters",
      fill = "k param") +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```


Take a close look at the results. When we modulate nfeatures or nPCs, we don't directly see changes in the number of celltypes found. But, like we saw in the previous sessions, modulating the k.param and the clustering resolution have outsized effects on the number of clusters found.

But if we're looking for a rare celltype, we must include more information, right? It makes most sense to increase both the nfeatures, nPCs, AND clustering resolution to find that celltype - because we need to make sure we are including the genes that define the celltype, and making small enough clusters to be able to find it. 


## Comparing subclustering  - using full dataset HVGs within only the subset
To do this we will focus on the T cell compartment.

First let's process our T cell subset object with the HVG obtained from the whole dataset - `hvg_full`:
```{r}
tse_full <- tse %>%
    NormalizeData() %>%
    ScaleData(
        verbose = FALSE,
        features = hvg_full) %>% 
    RunPCA(
        features = hvg_full,
        npcs = 20,
        verbose = FALSE) %>%
    FindNeighbors() %>%
    FindClusters(resolution = c(0.05, 0.1, 0.15, 0.2), verbose = FALSE)

# Visualize these clusters
DimPlot(
    tse_full,
    reduction = 'umap',
    group.by = c("RNA_snn_res.0.05", "RNA_snn_res.0.1",
                 "RNA_snn_res.0.15", "RNA_snn_res.0.2"))

dim_full <- DimPlot(
    tse_full,
    reduction = 'umap',
    group.by = "RNA_snn_res.0.15")
```

Now let's recompute the HVG for the T cell subset to capture the variability within that subset:
```{r}
tse_sub <- tse %>%
    FindVariableFeatures(
        method = "vst",
        nfeatures = 3000,
        verbose = FALSE) %>%
    ScaleData(verbose = FALSE, features = VariableFeatures(.)) %>% 
    RunPCA(
        npcs = 20,
        verbose = FALSE
    ) %>%
    FindNeighbors() %>%
    FindClusters(resolution = c(0.05, 0.1, 0.15, 0.2), verbose = FALSE) %>%
    RunUMAP(dims = 1:20, verbose = FALSE)

# Visualize these clusters
DimPlot(
    tse_sub,
    reduction = 'umap',
    group.by = c("RNA_snn_res.0.05", "RNA_snn_res.0.1",
                 "RNA_snn_res.0.15", "RNA_snn_res.0.2"))

dim_sub <- DimPlot(
    tse_sub,
    reduction = 'umap',
    group.by = "RNA_snn_res.0.15")
```

Right off the bat, how do these UMAPs compare to each other
```{r fig.width=12, fig.height=5}
dim_full + dim_sub
```

What you're probably wondering first is, hey would I have found these clusters if I had just increased the number of clusters I used? 
```{r}
data_alluvial <- data.frame(
    bc = colnames(tse_full),
    full_hvg = tse_full$RNA_snn_res.0.15,
    sub_hvg = tse_sub[, colnames(tse_full)]$RNA_snn_res.0.15) %>% 
    dplyr::count(full_hvg, sub_hvg)

ggplot(data = data_alluvial,
       aes(axis1 = full_hvg, axis2 = sub_hvg, y = n)) +
    geom_alluvium(aes(fill = full_hvg), width = 0.1) +
    geom_stratum(width = 0.1) +
    geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
    theme_minimal() +
    labs(title = "Alluvial plot of Clustering using full data HVG or  subcluster HVG",
         x = "Cluster assignment",
         y = "N")

```

Both clustering resolutions seem to be very similar but using specific HVG we are able to detect one more cluster at the same resolution and, *in theory*, the clusters should be more specific.

If we check for example the overlap of highly variable features between the two methods, we'll find there are very few overlapping

```{r}
table(VariableFeatures(tse_sub) %in% hvg_full)
head(setdiff(VariableFeatures(tse_sub),  hvg_full), n = 50)
intersect(VariableFeatures(tse_sub),  hvg_full)
```

We can see how by recomputing the HVG we replace 33% of the HVG genes which capture the variability present in the T cell subset. 

It looks like UMAP_1 is clearly separating 2 populations... let's look at some QC metrics to see what might be going on by looking at the `predicted.id`
```{r}
DimPlot(
    tse_sub,
    dims = c(1, 2),
    reduction = "pca",
    group.by = "predicted.id",
    label = TRUE)
```

It appears that we have some myeloid and B cells within our T cell subset.... Let's check the PCA loadings
```{r}
# Examine and visualize PCA results a few different ways
print(tse_sub[["pca"]], dims = 1:10, nfeatures = 15)
```

Some interesting PCs are the following:

-   PC1 contains a lot of proliferation related genes
-   PC5 contains a lot of B cell related genes in the negative loadings
-   PC8 contains a lot of myeloid genes with high loadings

```{r fig.width=12, fig.height=5}
DimPlot(
    tse_sub,
    dims = c(1, 5),
    reduction = "pca",
    group.by = "predicted.id",
    label = TRUE) | DimPlot(
    tse_sub,
    dims = c(1, 8),
    reduction = "pca",
    group.by = "predicted.id",
    label = TRUE)
```

Let's check some QC metrics to assess if we have potential doublets
```{r}
VlnPlot(
    tse_sub,
    features = c("pANN", "nCount_RNA", "nFeature_RNA"),
    group.by = "RNA_snn_res.0.15",
    pt.size = 0
)
```

Clusters 6 & 7 have elevated pANN scores while cluster 3 has slightly elevated library complexity. Let's check some cell type genes to determine what might be going on:

```{r}
ct_genes <- c(
    # Proliferating genes
    "MKI67", "TOP2A", "STMN1",
    # B cell genes
    "CD79A", "CD79B", "MS4A1", 
    # Myeloid genes
    "S100A8", "S100A9", "CD14",
    "FCGR3A", "LYZ", "VCAN",
    # T cell genes
    "CD3D", "CD3E", "CD8B",
    "TRAC", "TRBC1", "TRDC",
    # NK genes
    "NCR1", "NCR2", "NCR3",
    "KLRF1", "KLRC2"
)

Seurat::DotPlot(
  object = tse_sub,
  features = ct_genes,
  group.by = "RNA_snn_res.0.15",
  col.min = 0,
  dot.min = 0) +
  ggplot2::scale_x_discrete(
    breaks = ct_genes) +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 60, hjust = 1)) +
  ggplot2::labs(x = "", y = "")
```

Clusters 6 and 7 seem to be proliferating cells. 6 appeard to have a mix of T and myeloid cells and 7 are B cells. Moreover, cluster 3 is simultaneously expressing Myeloid and T cell genes which could be an indication that these are doublets. Let's double check these cells are in fact doublets:

```{r}
# Scale gene expression of genes of interest
tse_sub <- ScaleData(tse_sub, features = ct_genes)
DoHeatmap(
    tse_sub,
    features = ct_genes,
    group.by = "RNA_snn_res.0.15")
```

Effectively, cluster 3 are doublets!

### T cell clean up 

The whole purpose of iterative subclustering is to capture the biological variability of a specific cell type. Clearly, our level 1 annotation of T cells included more than just T cells, for the prupose of this notebook let's simulate a level-3 annotation where we removed clusters not of interest and focus on T cells!

```{r}
# Keep only clusters 0, 1, 2, 4, 5
tse_sub <- tse_sub[, tse_sub$RNA_snn_res.0.15 %in% c(0, 1, 2, 4, 5)]
```

Reprocess it -
```{r}
tse_sub <- tse_sub %>%
    FindVariableFeatures(
        method = "vst",
        nfeatures = 3000,
        verbose = FALSE) %>%
    ScaleData(verbose = FALSE, features = VariableFeatures(.)) %>% 
    RunPCA(
        npcs = 50,
        verbose = FALSE
    )

# Save HVG for T cells only
hvg_t <- VariableFeatures(tse_sub)

# Look at the elbow plot
ElbowPlot(tse_sub, ndims = 50)

tse_sub <- tse_sub %>% 
    FindNeighbors(dims = 1:30, verbose = FALSE) %>%
    FindClusters(resolution = c(0.15, 0.2, 0.25, 0.3), verbose = FALSE) %>%
    RunUMAP(dims = 1:30, verbose = FALSE)
```

Let's take a look at these clusters
```{r fig.width=12, fig.height=10}
DimPlot(
    tse_sub,
    reduction = 'umap',
    group.by = c(
        "RNA_snn_res.0.15", "RNA_snn_res.0.2",
        "RNA_snn_res.0.25",  "RNA_snn_res.0.3"))

dim_sub <- DimPlot(
    tse_sub,
    reduction = 'umap',
    group.by = c("RNA_snn_res.0.15"))
```

As showcased in the clustering algorithm a data-driven way to guide the decision making of the right clustering would be to run the Silhouette Analysis. For the purpose of this notebook we are going to move forward with 0.15.

```{r fig.width=12, fig.height=5}
dim_full + dim_sub
```

Let's compare the clusters with those obtained with the original full HVG genes
```{r}
temp_df <- tse_sub@meta.data %>%
    rownames_to_column("bc") %>%
    dplyr::select(bc, RNA_snn_res.0.15) %>%
    dplyr::rename(sub_hvg = RNA_snn_res.0.15)
    

data_alluvial2 <- tse_full@meta.data %>%
    rownames_to_column("bc") %>%
    dplyr::rename(full_hvg = RNA_snn_res.0.15) %>%
    left_join(temp_df, by = "bc") %>%
    mutate(sub_hvg = if_else(is.na(sub_hvg), "removed", sub_hvg)) %>%
    dplyr::count(full_hvg, sub_hvg)

ggplot(data = data_alluvial2,
       aes(axis1 = full_hvg, axis2 = sub_hvg, y = n)) +
    geom_alluvium(aes(fill = sub_hvg), width = 0.1) +
    geom_stratum(width = 0.1) +
    geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
    theme_minimal() +
    scale_fill_brewer(palette = "Dark2")
    labs(title = "Alluvial plot of Clustering using full data HVG or  subcluster HVG",
         x = "Cluster assignment",
         y = "N")
```

### Annotation playground

Let's find the marker genes of this new clustering
```{r}
Idents(tse_sub) <- tse_sub$RNA_snn_res.0.15
mgs <- FindAllMarkers(
    tse_sub,
    logfc.threshold = 0.25,
    only.pos = TRUE,
    min.pct = 0.25)

DT::datatable(mgs, filter = "top")
```

Do you think you can annotate these new clusters....

#### Cluster 1

Let's look at genes that are differentially expressed

```{r fig.height=12, fig.width=15}
c1 <- c(
    "KLRF1", "FCER1G", "FCGR3A",
    "TRDC", "GZMB", "GNLY")
FeaturePlot(
    tse_sub,
    features = c(c1),
    ncol = 3) +
    dim_sub

VlnPlot(
    tse_sub,
    features = c(c1),
    group.by = "RNA_snn_res.0.15") +
    dim_sub
```

#### Cluster 4
```{r fig.height=12, fig.width=15}
c4 <- c(
    "KLRF1", "FCER1G", "FCGR3A",
    "TIGIT", "CX3CR1", "KLRC2")

FeaturePlot(
    tse_sub,
    features = c(c4),
    ncol = 3) +
    dim_sub

VlnPlot(
    tse_sub,
    features = c(c4),
    group.by = "RNA_snn_res.0.15",
    pt.size = 0) +
    dim_sub

```

We can see how TIGIT is a gene uniquely expressed in cluster 4 which has come off of 0. How would this look like in the embedding with the full dataset
```{r fig.width=6, fig.height=5}
FeaturePlot(
    tse_full,
    features = "TIGIT")
```

#### Cluster 7

This cluster seems to be expressin Hemoglobin and MHC2 genes....
```{r fig.height=15, fig.width=15}
c7 <- c(
    "KLRF1", "FCER1G", "FCGR3A",
    "HBB", "HBA1", "HBA2",
    "HLA-DQA1", "HLA-DQA2")

FeaturePlot(
    tse_sub,
    features = c(c7),
    ncol = 3) +
    dim_sub

VlnPlot(
    tse_sub,
    features = c(c7),
    group.by = "RNA_snn_res.0.15",
    pt.size = 0) +
    dim_sub

```


#### Annotate
```{r eval=FALSE}
tse_sub@meta.data <- tse_sub@meta.data %>%
  dplyr::mutate(
    annotation_lvl2 = dplyr::case_when(
      RNA_snn_res.0.15 == 0 ~ "NK",
      RNA_snn_res.0.15 == 1 ~ "",
      RNA_snn_res.0.15 == 2 ~ "",
      RNA_snn_res.0.15 == 3 ~ "",
      RNA_snn_res.0.15 == 4 ~ "NK TIGIT+/CX3CR1+/KLRC2+",
      RNA_snn_res.0.15 == 5 ~ "",
      RNA_snn_res.0.15 == 6 ~ "",
      RNA_snn_res.0.15 == 7 ~ "Doublets/lowQ",
      RNA_snn_res.0.15 == 8 ~ ""
      )
  )

DimPlot(tse_sub, group.by = "annotation_lvl2")
```


### Comparing PCA

Lastly, lets compare the PC spaces between using HVG selected from the whole data or from the cleaned up T cell subset

So let's take a closer look at what changes in the PCA latent spaces. Maybe the information we need is there. 

```{r}
latent_full <- tse_full@reductions$pca@cell.embeddings
loadings_full <- tse_full@reductions$pca@feature.loadings
var_full <- tse_full@reductions$pca@stdev
t_full <- tse_full@reductions$pca@misc$total.variance


latent_sub <- tse_sub@reductions$pca@cell.embeddings
loadings_sub <- tse_sub@reductions$pca@feature.loadings
var_sub <- tse_sub@reductions$pca@stdev
t_sub <- tse_sub@reductions$pca@misc$total.variance

var_full_df <- data.frame(
    PC = 1:length(var_full),
    Variance = var_full^2 / t_full,
    Set = "Full HVG")
var_sub_df <- data.frame(
    PC = 1:length(var_sub),
    Variance = var_sub^2 / t_sub,
    Set = "Clean HVG")

# Calculate cumulative variance explained
var_full_df$CumulativeVariance <- cumsum(var_full_df$Variance)
var_sub_df$CumulativeVariance <- cumsum(var_sub_df$Variance)

# Combine the datasets
combined_variance <- bind_rows(var_full_df, var_sub_df)

# Plotting the variance explained and cumulative variance
ggplot(combined_variance, aes(x = PC)) +
    geom_line(aes(y = CumulativeVariance, color = Set), size = 1.2) +
    geom_point(aes(y = CumulativeVariance, color = Set), size = 2) +
    scale_color_manual(values = c("blue", "red")) +
    scale_linetype_manual(values = c("solid", "dashed")) +
    theme_minimal() +
    labs(title = "Cumulative Variance Explained",
         x = "Principal Component",
         y = "Proportion of Variance Explained") +
    guides(color = guide_legend(title = "Parameter Set"), 
           linetype = guide_legend(title = "Variance Type"))

```

Both seem to be very similar, and it makes sense, since they are gene sets obtained by selecting the most variable genes from their respective spaces. However, the biological variance they capture is very different! We can look at that by comparing how the PC loadings of genes of interest change.

```{r}
# Function to compare PC loadings between 2 embeddings, it basically compares the difference between the max value of each gene between both PC spaces
compare_pca_loadings <- function(loadings1, loadings2, top_n = 20, cell_type_markers = NULL,
                                  loadings1_name = deparse(substitute(loadings1)), 
                                  loadings2_name = deparse(substitute(loadings2))) {
    all_genes <- union(rownames(loadings1), rownames(loadings2))

    # Initialize matrices to store aligned loadings with genes set to 0 by default
    loadings1_aligned <- matrix(0, nrow = length(all_genes), ncol = ncol(loadings1), 
                                dimnames = list(all_genes, colnames(loadings1)))
    loadings2_aligned <- matrix(0, nrow = length(all_genes), ncol = ncol(loadings2), 
                                dimnames = list(all_genes, colnames(loadings2)))

    # Fill in the existing values from each matrix
    loadings1_aligned[rownames(loadings1), ] <- loadings1
    loadings2_aligned[rownames(loadings2), ] <- loadings2

    # Check for zero values immediately after filling in values
    loadings1_zero <- apply(loadings1_aligned, 1, function(x) all(x == 0))
    loadings2_zero <- apply(loadings2_aligned, 1, function(x) all(x == 0))

    outlines <- character(length(all_genes))
    outlines[loadings1_zero] <- "orange"
    outlines[loadings2_zero] <- "blue"
    # outlines[loadings1_zero & loadings2_zero] <- "white" # Both are zero

    max_loadings1 <- apply(abs(loadings1_aligned), 1, max)
    max_loadings2 <- apply(abs(loadings2_aligned), 1, max)

    # Calculate the differences between the maximum absolute loadings across all PCs
    loadings_difference <- max_loadings2 - max_loadings1

    # Determine the direction of the difference
    directionality <- ifelse(loadings_difference > 0, paste("Higher in", loadings2_name), paste("Higher in", loadings1_name))

    fillpal <- c('steelblue','salmon')
    names(fillpal) = c(paste("Higher in", loadings2_name), paste("Higher in", loadings1_name))

    # Create a data frame for plotting
    genes_differences_df <- data.frame(
        Feature = rownames(loadings1_aligned),  # Assuming both matrices have the same rownames
        Difference = loadings_difference,
        Direction = directionality,
        Outline = outlines[match(rownames(loadings1_aligned), all_genes)]
    )

    genes_differences_df <- genes_differences_df %>% mutate(
                MaxAbsLoadings1 = ifelse(Direction == names(fillpal)[1], -max_loadings1, max_loadings1),
                MaxAbsLoadings2 = ifelse(Direction == names(fillpal)[2], -max_loadings2, max_loadings2))

    if (!is.null(cell_type_markers)) {
        marker_genes <- unlist(cell_type_markers, use.names = FALSE)
        genes_differences_df <- genes_differences_df %>%
            dplyr::filter(Feature %in% marker_genes) %>%
            dplyr::mutate(CellType = NA)  # Assign NA initially

        for (cell_type in names(cell_type_markers)) {
            genes_differences_df$CellType[genes_differences_df$Feature %in% cell_type_markers[[cell_type]]] <- cell_type
        }
        
        
        plot <- ggplot(
            genes_differences_df,
            aes(x = reorder(Feature, Difference), y = Difference, fill = Direction)) +
            geom_col() +
            coord_flip() +
            theme_minimal() +
            scale_fill_manual(values = fillpal) +
            labs(title = "Gene Loadings Differences by Cell Type",
                 subtitle = paste("Comparing", loadings1_name, "and", loadings2_name),
                 x = "Gene",
                 y = "Difference in Loadings") +
            guides(fill = guide_legend(title = "Where Loadings are Higher")) +
            facet_wrap(~CellType, scales = "free_y", ncol = 1, drop = TRUE)
    } else {
        genes_differences_df <- genes_differences_df %>%
            dplyr::arrange(desc(Difference)) %>%
            dplyr::slice(1:top_n)

        plot <- ggplot(
            genes_differences_df,
            aes(x = reorder(Feature, Difference), y = Difference, fill = Direction)) +
            geom_col(show.legend = FALSE) +
            scale_color_manual(
                name = "Outline Color",
                values = c("green" = "green", "blue" = "blue", "purple" = "purple"),
                labels = c(paste("Zero in", loadings1_name),
                           paste("Zero in", loadings2_name),
                           "Zero in Both")) +
            coord_flip() +
            theme_minimal() +
            scale_fill_manual(values = fillpal) +
            labs(
                title = paste("Top", top_n, "Genes with Greatest Differences in Loadings"),
                subtitle = paste("Comparing", loadings1_name, "and", loadings2_name),
                x = "Gene",
                y = "Difference in Loadings") +
            guides(fill = guide_legend(title = "Where Loadings are Higher"))
    }

    return(plot)
}
```

Let's compare which genes change the most between the full HVG and clean HVG
```{r fig.width=6, fig.height=9}
# Ensure both matrices have the same genes in the same order
common_genes <- intersect(rownames(loadings_full), rownames(loadings_sub))
loadings_full_aligned <- loadings_full[common_genes, , drop = FALSE]
loadings_sub_aligned <- loadings_sub[common_genes, , drop = FALSE]

# Determine high loadings
cutoff_l <- quantile(abs(as.matrix(loadings_full_aligned)), 0.95)
cutoff_h <- quantile(abs(as.matrix(loadings_sub_aligned)), 0.95)

high_loadings_full <- apply(abs(loadings_full_aligned), 1, max) > cutoff_l
high_loadings_sub <- apply(abs(loadings_sub_aligned), 1, max) > cutoff_h

# Identify features that are high in _h but not high in _l
target_features <- names(which(high_loadings_sub & !high_loadings_full))

# Prepare loadings of these target features for plotting
target_loadings <- loadings_sub_aligned[target_features, , drop = FALSE]

# Convert to long format for ggplot using pivot_longer
loadings_fullong <- as.data.frame(target_loadings) %>%
  tibble::rownames_to_column("Feature") %>%
  pivot_longer(
    cols = -Feature,
    names_to = "PC",
    values_to = "Loading"
  )

# Example usage:
compare_pca_loadings(loadings_full, loadings_sub, top_n = 40)

```

Many of these genes are trained immunity genes. At this point we could keep some rare positive-control celltype in mind, like ILC3s or something else we might expect to find in this dataset

```{r}
# Define a list of cell type markers
cell_type_markers <- list(
    Tcell = c("TRAC", "TRBC1", "TRBC2", "CD3D", "CD3E"),
    CD8cyto = c("CD8A", "CD8B", "GZMA", "NKG7", "GZMK"),
    CD4 = c("CD4"),
    Trespone = c("CD40LG", "CD28"),
    Naive = c("CCR7", "LEF1", "TCF7"),
    Treg = c("FOXP3", "CTLA4", "IL2RA"),
    NK = c("NCR1", "NCR2", "NCR3", "KLRF1", "KLRC2"),
    Myeloid = c("S100A8", "S100A9", "CD14", "FCGR3A", "LYZ", "VCAN"),
    Bcell = c("CD79A", "CD79B", "MS4A1")
)

compare_pca_loadings(loadings_full, loadings_sub, cell_type_markers = cell_type_markers)
```

And if we compare the loadings for genes of interest
```{r fig.width=6, fig.height=9}
compare_pca_loadings(loadings_full, loadings_sub, cell_type_markers = cell_type_markers)
```

## Session Info
```{r}
sessionInfo()
```