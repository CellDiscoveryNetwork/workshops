---
title: "6 - Clustering"
author: "CDN team"
date: last-modified
date-format: "[Last compiled on] D MMMM, YYYY"
format:
  html:
    toc: true
    toc_float: true
    toc-location: left
    toc-depth: 4
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = "100%", fig.align='center', 
                      message = FALSE, warning = FALSE, cache = FALSE)
options(width = 1200)
```

# Clustering

## Introduction

Clustering takes place on good quality cells after dimensionality reduction. After filtering out non-informative cells and reducing the dimensionality of our dataset, the data is ready to cluster. Clustering is the process of grouping cell identities based on their gene expression profiles. It is done by computing a nearest neighbor graph and then grouping cells based on their connectivity in this graph. To effectively cluster an experiment, it should be done iteratively so the least amount of information is lost or misidentified.

In this notebook, we learn:

-   Clustering in Seurat requires the computation of a nearest neighbor graph followed by the identification of clusters in this graph using functions `FindNeighbors()` and `FindClusters()`.

-   The resolution parameter in `FindClusters()` controls the granularity of the clustering. A higher resolution results in more clusters.

-   Clustering results can be evaluated quantitatively by looking at the sample and batch distribution across clusters and a silhouette analysis of the clusters.

## Review

We left off (last session) filtering out the poor quality data without regard for its distribution. Last week, we learned how principle components are calculated, what a latent space is, and defined a kNN (k-nearest neighbors) graph.

To review those:

We take a cell x gene matrix, normalize it, and reduce its dimensionality using PCA. We looked at an Elbow plot to determine the best number of PCs that accurately show the variance explained. After selecting the top 30 PCs, we generated a k-nearest neighbors (kNN) graph to represent the relationships between cells based on their gene expression profiles and ran `FindClusters()` to identify clusters of cells based on their neighborhood relationships. Kyle introduced Harmony as an integration technique to correct for batch effects and I just went over QC metrics including doublet detection that help us understand the quality and content of our data.

### Glossary

**PCA** - A dimensionality reduction technique that reduces the number of dimensions in a dataset while retaining as much variance as possible. The first principal component accounts for the most variance in the data, and each subsequent component accounts for less variance.

**Latent Space** - The latent space is the low-dimensional representation of the data that captures the most important features.

**kNN Graph** - A graph that represents the relationships between cells based on their gene expression profiles. Each cell is connected to its k (1, 20, 100) nearest neighbors in the graph.

### Resources

1.  [Current best practices in single-cell RNA-seq analysis: a tutorial](https://www.embopress.org/doi/full/10.15252/msb.20188746)
2.  [Bioconductor](https://bioconductor.org/books/3.13/OSCA.basic/quality-control.html)
3.  [Single Cell Best Practices](https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html)
4.  [Challenges in unsupervised clustering of single-cell RNA-seq data](https://www-nature-com.ezp-prod1.hul.harvard.edu/articles/s41576-018-0088-9)

## Load Libraries and Data

```{r}
if (!requireNamespace("dplyr", quietly = TRUE))
    install.packages('dplyr')
if (!requireNamespace("tidyverse", quietly = TRUE))
    install.packages('tidyverse')
if (!requireNamespace("Seurat", quietly = TRUE))
    install.packages('Seurat')
if (!requireNamespace("colorBlindness", quietly = TRUE))
    install.packages('colorBlindness')
if (!requireNamespace("RColorBrewer", quietly = TRUE))
    install.packages('RColorBrewer')
if (!requireNamespace("cluster", quietly = TRUE))
    install.packages('cluster')
if (!requireNamespace("viridis", quietly = TRUE))
    install.packages('viridis')
if (!requireNamespace("ggplot2", quietly = TRUE))
    install.packages('ggplot2')
if (!requireNamespace("ggalluvial", quietly = TRUE))
    install.packages("ggalluvial") 
```

```{r}
library(dplyr)
library(Seurat)
library(tidyverse)
library(RColorBrewer)
library(colorBlindness)
library(DoubletFinder)
library(cluster)
library(viridis)
library(ggplot2)
library(ggalluvial)

set.seed(687)
```

Load Data

```{r}
# Load the Seurat object with doublet and batch information
se <- readRDS('../data/Covid_Flu_Seurat_Object_Quality.rds')
se 

# Set color palette for cell types
pal <- paletteMartin
names(pal) <- sort(unique(se$Celltype))

donor_pal <- c(
    "#66C2A4", "#41AE76", "#238B45", "#006D2C",
    "#41B6C4", "#1D91C0", "#225EA8", "#253494", "#081D58",
    "#FFEDA0", "#FED976", "#FEB24C", "#f79736", "#FD8D3C",
    "#FC4E2A", "#E31A1C", "#BD0026", "#ad393b", "#800000", "#800050")

names(donor_pal) <- c(
    "Normal 1", "Normal 2", "Normal 3", "Normal 4",
    "Flu 1", "Flu 2", "Flu 3", "Flu 4", "Flu 5",
    "nCoV 1", "nCoV 2", "nCoV 3", "nCoV 4", "nCoV 5",
    "nCoV 6", "nCoV 7", "nCoV 8", "nCoV 9", "nCoV 10", "nCoV 11"  
)
```

## Set Up

### PCA

Let's first look at the data according to the top 2 principle components.

```{r, fig.width=6, fig.height=6}
celltype_pca <- DimPlot(
        se,
        reduction = "pca",
        group.by = 'Celltype',
        cols = pal
        ) 

celltype_pca
```

### Construct the kNN graph with `FindNeighbors()`:

`FindNeighbors()` is the Seurat function that calculates the k-nearest neighbors of each cell in PCA space. The number of neighbors used for this calculation is controlled by the k.param parameter with a default value of 30. It computes pairwaise distances between cells based on their gene expression using comming algorithms such as: euclidean distance, manhattan distance, Pearson correlation distance, and cosine similarity. choice matters.

From [BioStars](https://www.biostars.org/p/9572463/):

*`FindNeighbors()` is a function that is used to find the nearest neighbors of your single cell data point within a dataset. It works by calculating the neighborhood overlap (Jaccard index) between every cell and its k.param nearest neighbors. It's often employed in various applications such as anomaly detection and dimensionality reduction. The concept is that given a data point, you want to identify the closest data points to it based on some similarity metric, such as Euclidean distance or cosine similarity. This helps to identify similar points in the dataset, which can be useful for making predictions or understanding the distribution of the data.*

The default values of FindNeighbors() are:

<img src="../data/FindNeighbors.png" width="200"/>

Let's modify these to fit our analysis:

```{r}
se <- se %>% 
    FindNeighbors( 
      object = se,
      reduction = "pca",
      dims = 1:30,
      k.param = 30,
      verbose = FALSE
    )
```

```{r}
# Look at the k-nearest neighbors (nn) and shared nearest neighbors (snn) graphs computed
se@graphs
```

### FindClusters

`FindClusters()` is used for identifying clusters of cells based on their neighborhood relationships typically obtained from PCA or t-SNE. It inputs the graph made from `FindNeighbors()` and outputs cluster assignments for each cell found at `se@meta.data$seurat_clusters`.

The resolution parameter controls the granularity of the clustering. Higher values of resolution will result in more clusters, while lower values will result in fewer clusters. The default value is 0.8.

From BioStars:\
*`FindClusters()` is a function used for clustering data points into groups or clusters based on their similarity. It uses a graph-based clustering approach and a Louvain algorithm. Clustering is an unsupervised learning technique where the algorithm groups similar cells together without any predefined labels. The goal is to find patterns and structure in your data. The number of clusters and the algorithm used can vary based on the problem and data characteristics. Common clustering algorithms include K-means, hierarchical clustering, and DBSCAN.*

<img src="../data/FindClusters.png" width="200"/>\
*where 'algorithm' =*

*1 - original Louvain algorithm*

*2 - Louvain algorithm with multilevel refinement*

*3 - SLM (Smart Local Moving) algorithm*

*4 - Leiden algorithm*

*See `?FindClusters` for more information.*

## Clustering

Clustering is considered a classical unsupervised machine learning task. Seurat uses the community detection algorithm, Leiden, to identify cell clusters. A community detection algorithm identifies groups of nodes in a network that as densely connected. The Leiden algorithm connects cells by finding tightly connected communities in the shared nearest neighbor graph computed in `FindNeighbors.` Shared nearest neighbor graphs are more robust than k-nearest neighbors graphs. sNN graphs weight edges based on the number of shared edges with other cells. Leiden is a 2019 improvement on the Louvain algorithm so it is common to see both in scRNA-seq analysis.

In clustering, the goal is not to see how many clusters you can pull apart but it is an iterative process. Especially in the first pass, you want to pull apart main cell groups such as epithelial cells and immune cells so you can further refine clusters to extract more granular cell types in the next iteration.

After clustering, we'll review some cluster validation techniques to qualitatively and quantitatively check the quality of the clustering results.

```{r}
se <- FindClusters(
      object = se,
      resolution = c(0.01, 0.05, 0.1, 0.15, 0.2,0.25)) 
# Find clusters based on nearest neighbors at a resolution of 0.5
```

```{r}
# Results seen at RNA_snn_res in metadata
se@meta.data %>% select(contains("RNA_snn_res")) %>% colnames()
```

#### RunUMAP

UMAP runs on the PCA space. The dims parameter specifies which dimensions of the PCA space to use for the UMAP calculation. The default value is 1:30, which uses all dimensions. The n.components parameter specifies the number of dimensions in the UMAP embedding. The default value is 2.
```{r}
se <- se %>% 
    RunUMAP(dims = 1:30, verbose = FALSE) # Run UMAP 
```

#### Visualize Clusters

```{r, fig.width=15, fig.height=10}
DimPlot(
    se,
    group.by = c(
        "RNA_snn_res.0.01", "RNA_snn_res.0.05",
        "RNA_snn_res.0.1", "RNA_snn_res.0.15",
        "RNA_snn_res.0.2", "RNA_snn_res.0.25"),
    label = TRUE
)
```

Community detection graphs split whole datasets into more groups at higher resolution and do not subcluster based on major clusters that are present at lower resolutions. Clustering at a low resolution splits the dataset into a certain number of groups while clustering at a high resolution draws different lines on that same larger corpus of data. Below we show how this method of clustering (community detection) is different from hierarchical clustering.

```{r}
se_1 <- se %>%
  FindClusters(resolution = 0.25) 

metadata <- se@meta.data
metadata_1 <- se_1@meta.data
plot_data <- as.data.frame(table(metadata$seurat_clusters, metadata_1$seurat_clusters))
colnames(plot_data) <- c("Cluster 0.05", "Cluster 0.25", "Freq")
```

```{r, fig.width=12, fig.height=8}
ggplot(plot_data,
       aes(axis1 = `Cluster 0.05`, axis2 = `Cluster 0.25`, y = Freq)) +
    geom_alluvium(aes(fill = `Cluster 0.05`), width = 0.1) +
    geom_stratum(width = 0.1) +
    geom_text(stat = "stratum", aes(label = after_stat(stratum))) +
    scale_x_discrete(limits = c("Cluster 0.05", "Cluster 0.25"), expand = c(0.15, 0.05)) +
    labs(title = "Compare Cluster Resolution of 0.05 and 0.25",
         x = "Clusters",
         y = "Count") +
    theme_minimal()
```

#### Different Resolutions

0.01 vs 0.05 Resolution

```{r, fig.width=18, fig.height=5}
DimPlot(
    se,
    group.by = c(
        "Celltype","RNA_snn_res.0.05", "RNA_snn_res.0.1"),
    label = TRUE
    )
```
Comparing the 0.05 and the 0.1 resolutions, Cluster 0 in the 0.05 resolution appears to split into 2 looking at Clusters 1 and 2 in resolution 0.1. While this seems helpful in sifting through the data, we've decided to keep the large blobs together. This saves us visibility of our dataset in the second level of annotation. Resolution 0.05 has the best distribution, but let's quantitatively analyze it's clusters quality. 

## Cluster Metrics

### Cluster Diversity

Splitting the clusters by cluster size and sample diversity allows us to make sure not one sample is being clustered separately from others.
```{r}
seurat_clusters <- "RNA_snn_res.0.05"
diversityPerGroup <- function(df, species, group, diversity_metric = 'simpson') {
  # Convert strings to symbols for curly-curly operator
  species_sym <- rlang::sym(species)
  group_sym <- rlang::sym(group)
  # Count groups per species directly using curly-curly
  tierNcount <- df %>%
    group_by({{species_sym}}) %>%
    count({{group_sym}}, name = "n") %>% ungroup
  # Pivot table to allow vegan::diversity call
  tierNwide <- tierNcount %>%
    pivot_wider(names_from = {{group_sym}}, values_from = n, values_fill = list(n = 0))
  # Use rownames of species for the diversity function, which needs a dataframe
  tierNwide_df <- as.data.frame(tierNwide)
  # species column must be first
  tierNwide_df <- tierNwide_df %>% select({{species}}, everything())
  rownames(tierNwide_df) <- tierNwide_df[, 1]
  tierNwide_df <- tierNwide_df[, -1]
  # Calculate diversity
  diversity_values <- vegan::diversity(tierNwide_df, index = diversity_metric)
  # Prepare result as a dataframe
  result <- data.frame(
    species = rownames(tierNwide_df),
    diversity = diversity_values,
    row.names = NULL
  )
  # Rename diversity column
  names(result)[1] <- species
  names(result)[2] <- sprintf('%s_diversity', group)
  return(result)
}

# Calculate simpson's diversity per cluster
clusterMetrics <- diversityPerGroup(se_1@meta.data,
                        species = 'RNA_snn_res.0.05',
                        group = 'Sample ID',
                        diversity_metric = 'simpson')

# Calculate number of cells per cluster and join to metrics table
clusterMetrics <- clusterMetrics %>% left_join(se_1@meta.data %>% count(RNA_snn_res.0.05))

# clusterMetrics
```

```{r}

seurat_clusters <- "RNA_snn_res.0.05"
clusterMetrics$seurat_clusters <- as.numeric(clusterMetrics$RNA_snn_res.0.05)

div <- ggplot(clusterMetrics, aes(x = seurat_clusters, y = n)) +
  geom_segment(aes(x = seurat_clusters, xend = seurat_clusters, y = 0, yend = n),
               size = 1.5, color = 'grey80') + # Draw lines for lollipops
  geom_point(aes(colour = `Sample ID_diversity`), size = 5) + # Add colored lollipop 'heads', coloring by 'Sample ID_diversity'
  scale_y_log10() +
  scale_x_continuous(breaks = seq(0,20)) + 
  scale_colour_viridis(option = "C", name = "Sample ID Diversity", direction = 1, limits = c(0,1)) + # Colorblind-friendly, vibrant color palette
  theme_minimal(base_size = 10) +
  theme(legend.position = "bottom",
        axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14), 
        title = element_text(size = 16)) +
  labs(x = "Seurat Clusters",
       y = "cluster size (log-scaled)",
       title = "Cluster Diversity Metrics") +
  guides(colour = guide_colourbar(title.position = "top", title.hjust = 0.5))

div
```
Cluster 4 appears to be the least diverse in terms of sample diversity. Let's investigate which samples are in each cluster to see if there is any bias.

Plot sample distribution per cluster

```{r, fig.width = 8, fig.height = 6}
# Assuming se_1@meta.data has columns 'seurat_clusters' and 'Sample ID'

# Prepare the data for plotting
plot_sample <- se_1@meta.data %>%
  count(RNA_snn_res.0.05, `Sample ID`) %>%
  group_by(RNA_snn_res.0.05) %>%
  mutate(proportion = n / sum(n)) %>%
  ungroup()

# Create a stacked bar plot
ggplot(plot_sample, aes(x = factor(RNA_snn_res.0.05), y = proportion, fill = `Sample ID`)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(x = "Seurat Clusters", y = "Proportion", fill = "Sample ID",
       title = "Distribution of Sample IDs Across Clusters") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values = donor_pal)
```
Sample `Flu 1` appears to make up the majority of Cluster 4.

Another way to visualize cluster diversity is through a stacked bar plot instead of lollipops. This provides a super clear way to compare these numercial metrics side by side.

```{r, fig.width = 6, fig.height = 4}
p2 <- ggplot(clusterMetrics, aes(y=as.character(seurat_clusters), fill=`Sample ID_diversity`, x = 1, label = n)) +
  geom_tile(colour = "white") +
  geom_text(nudge_x = 1.5, size = 3) +
  geom_text(aes(label = signif(`Sample ID_diversity`, 2)),size = 3) +
  scale_fill_distiller(palette = "Spectral", limits = c(0,1)) + theme_classic() +
  coord_fixed(ratio = 0.25) + 
  expand_limits(x = c(0.5,3)) +
  labs(x = "Diversity                                   Size") +
  theme(axis.text.y = element_text(hjust = 1, vjust = 0.5, size = 12),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y = element_text(size = 15),
        legend.key.size = unit(1, 'cm'),
        legend.title = element_text(size=10), 
        legend.text = element_text(size=10)
  ) 
p2
```

Visualizing cluster diversity based on batch is also an important thing to look out for. This is similar to the QC motivation where these plots provide a way to explain your data and possible findings before claiming any biological phenomena.
```{r, fig.width = 8, fig.height = 6}
# Prepare the data for plotting
plot_batch <- se_1@meta.data %>%
  count(RNA_snn_res.0.05, batch) %>%
  group_by(RNA_snn_res.0.05) %>%
  mutate(proportion = n / sum(n)) %>%
  ungroup()

# Create a stacked bar plot
ggplot(plot_batch, aes(x = factor(RNA_snn_res.0.05), y = proportion, fill = batch)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(x = "Seurat Clusters", y = "Proportion", fill = "Batch",
       title = "Distribution of Batches Across Clusters") +
  # theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_manual(values = donor_pal)
```

### Silhouette Analysis

As covered in the last workshop, silhouette analysis is a way to measure how similar an object is to its own cluster compared to other clusters. The silhouette value ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.

```{r}
seurat_clusters <- se_1@meta.data$RNA_snn_res.0.05

pca_embeddings <- Embeddings(se, reduction = 'pca')

# Calculate silhouette widths
sil_scores <- silhouette(x = as.numeric(seurat_clusters), dist = dist(pca_embeddings))

# Extract silhouette scores
silhouette_data <- as.data.frame(sil_scores)
# Recover cell type names
silhouette_data$seurat_clusters <- as.character(seurat_clusters)

row.names(silhouette_data) <- row.names(pca_embeddings)

silhouette_arranged <- silhouette_data %>% 
  group_by(seurat_clusters) %>% 
  arrange(-sil_width)
```

```{r}
overall_average <- silhouette_arranged %>% 
  ungroup %>% 
  summarize(ave = as.numeric(mean(sil_width))) %>% 
  pull(ave)

full_plot <- ggplot(silhouette_arranged, 
                    aes(x = sil_width, 
                        y = seurat_clusters, 
                        fill = seurat_clusters, 
                        group = seurat_clusters)) +
    geom_bar(stat = "identity", position = 'dodge2') +
    geom_vline(xintercept = overall_average,
               color = 'red',
               linetype = 'longdash') +
    theme_minimal() +
    labs(title = "Silhouette Analysis",
        y = "Cluster",
        x = "Silhouette width",
        fill = "Cluster") +
    theme(axis.text.y = element_text(hjust = 1, vjust = 0.5, size = 20),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y = element_text(size = 20),
        legend.position = "None")

full_plot
```
The dashed red lines shows the average silhouette width across all clusters. The silhouette width is a measure of how similar an object is to its own cluster compared to other clusters. A high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters. The mystery of Cluster 4 is shown a bit more clearly here as the plot shows that Cluster 4 is more similar to other clusters than to itself. 

So let's look at silhouette scores on a UMAP

```{r, fig.width = 10, fig.height = 5}
d5 <- DimPlot(se,
        reduction='umap',
        group.by='RNA_snn_res.0.05', 
        label = TRUE)

se_1$CellID <- row.names(se_1@meta.data)

sil_ids <- silhouette_data %>% rownames_to_column('CellID') %>% left_join(se_1@meta.data, by='CellID')
se_1 <- AddMetaData(se_1, sil_ids)

FeaturePlot(
  se_1, 
  feature = "sil_width") + 
  ggtitle('Silhouette width') + 
  scale_color_viridis(limits = c(-1,1), 
                        option = "magma") | d5
```

Lastly, we should look at cells that might be between cell types or proliferating. These are often cells in transition and can be clustered across the UMAP.
```{r, fig.width = 12, fig.height = 6}
p1 <- FeaturePlot(
  se,
  features = c("MS4A1")
)
p2 <- DimPlot(
    se,
    group.by = "RNA_snn_res.0.05",
    label = TRUE
  )
p1 | p2
```

## Extra: More on Clustering Algorithms

The Louvain algorithm was developed in 2008 and is a popular community detection algorithm used in scRNA-seq. *It recursively merges communities into a single node and executes the modularity clustering on the condensed graphs.*([Zhang](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10158997/)) Both *Seurat* and *scanpy* use Louvain as the default clustering algorithm.

![](../data/clustering.jpeg){width="900"}\
*Leiden Algorithm*

The Leiden algorithm was published in 2020 as an improvement of the Louvain algorithm. *Leiden creates clusters by taking into account the number of links between cells in a cluster versus the overall expected number of links in the dataset. It computes a clustering on a KNN graph obtained from the PC reduced expression space. It starts with an initial partition where each node from its own community. Next, the algorithm moves single nodes from one community to another to find a partition, which is then refined. Based on a refined partition an aggregate network is generated, which is again refined until no further improvements can be obtained, and the final partition is reached.* ([Single Cell Best Practices](https://www.sc-best-practices.org/clustering/clustering.html)).

There are a couple of popular clustering algorithms. There is no one way to cluster as clustering is a means of looking at the data from different angles. The most popular clustering algortihms are the louvain algorithm, leiden algorithm, hierarchical clustering, and k-means clustering. Seurat uses the Leiden algorithm by default which is an improvement on the Louvain algorithm.

## Session Info

```{r}
sessionInfo()
```
